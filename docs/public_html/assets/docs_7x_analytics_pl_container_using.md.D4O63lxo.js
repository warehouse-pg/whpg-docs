import{_ as n,c as a,o as s,ag as t}from"./chunks/framework.Ds6Eueu6.js";const h=JSON.parse('{"title":"Using PL/Container","description":"","frontmatter":{},"headers":[],"relativePath":"docs/7x/analytics/pl_container_using.md","filePath":"docs/7x/analytics/pl_container_using.md"}'),o={name:"docs/7x/analytics/pl_container_using.md"};function i(p,e,r,l,c,d){return s(),a("div",null,e[0]||(e[0]=[t(`<h1 id="using-pl-container" tabindex="-1">Using PL/Container <a class="header-anchor" href="#using-pl-container" aria-label="Permalink to &quot;Using PL/Container&quot;">​</a></h1><hr><p>This topic covers further details on:</p><ul><li><a href="#topic_resmgmt">PL/Container Resource Management</a></li><li><a href="#plc_notes">PL/Container Logging</a></li><li><a href="#topic_rh3_p3q_dw">PL/Container Function Limitations</a></li><li><a href="#using_functions">Developing PL/Container functions</a></li><li><a href="#remote_container">Configuring a Remote PL/Container</a></li></ul><h2 id="pl-container-resource-management" tabindex="-1"><a id="topic_resmgmt"></a>PL/Container Resource Management <a class="header-anchor" href="#pl-container-resource-management" aria-label="Permalink to &quot;&lt;a id=&quot;topic_resmgmt&quot;&gt;&lt;/a&gt;PL/Container Resource Management&quot;">​</a></h2><p>The Docker containers and the WarehousePG servers share CPU and memory resources on the same hosts. In the default case, WarehousePG is unaware of the resources consumed by running PL/Container instances. You can use WarehousePG resource groups to control overall CPU resource usage for running PL/Container instances.</p><p>PL/Container manages resource usage at two levels - the container level and the runtime level. You can control container-level CPU and memory resources with the <code>memory_mb</code> and <code>cpu_share</code> settings that you configure for the PL/Container runtime. <code>memory_mb</code> governs the memory resources available to each container instance. The <code>cpu_share</code> setting identifies the relative weighting of a container&#39;s CPU usage compared to other containers. See <a href="./../utility_guide/ref/plcontainer-configuration.html">plcontainer Configuration File</a> for further details.</p><p>You cannot, by default, restrict the number of running PL/Container container instances, nor can you restrict the total amount of memory or CPU resources that they consume.</p><p>Resource groups for external components such as PL/Container use Linux control groups (cgroups) to manage component-level use of CPU resources.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>CREATE RESOURCE GROUP plpy_run1_rg WITH (CONCURRENCY=10, CPU_MAX_PERCENT=10);</span></span></code></pre></div><p>You can create one or more resource groups to manage your running PL/Container instances. After you create a resource group for PL/Container, you assign the resource group to one or more PL/Container runtimes. You make this assignment using the <code>groupid</code> of the resource group. You can determine the <code>groupid</code> for a given resource group name from the <code>gp_resgroup_config</code> <code>gp_toolkit</code> view. For example, the following query displays the <code>groupid</code> of a resource group named <code>plpy_run1_rg</code>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>SELECT groupname, groupid FROM gp_toolkit.gp_resgroup_config</span></span>
<span class="line"><span> WHERE groupname=&#39;plpy_run1_rg&#39;;</span></span>
<span class="line"><span>                            </span></span>
<span class="line"><span> groupname   |  groupid</span></span>
<span class="line"><span> --------------+----------</span></span>
<span class="line"><span> plpy_run1_rg |   16391</span></span>
<span class="line"><span> (1 row)</span></span></code></pre></div><p>You assign a resource group to a PL/Container runtime configuration by specifying the <code>-s resource_group_id=rg\\_groupid</code> option to the <code>plcontainer runtime-add</code> (new runtime) or <code>plcontainer runtime-replace</code> (existing runtime) commands. For example, to assign the <code>plpy_run1_rg</code> resource group to a new PL/Container runtime named <code>python_run1</code>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>plcontainer runtime-add -r python_run1 -i pivotaldata/plcontainer_python_shared:devel -l python -s resource_group_id=16391</span></span></code></pre></div><p>You can also assign a resource group to a PL/Container runtime using the <code>plcontainer runtime-edit</code> command. For information about the <code>plcontainer</code> command, see <a href="./../utility_guide/ref/plcontainer.html">plcontainer</a> reference page.</p><p>After you assign a resource group to a PL/Container runtime, all container instances that share the same runtime configuration are subject to the CPU limit that you configured for the group. If you drop a PL/Container resource group while there are running container instances, WarehousePG terminates the running containers.</p><h3 id="configuring-resource-groups-for-pl-container" tabindex="-1"><a id="topic_resgroupcfg"></a>Configuring Resource Groups for PL/Container <a class="header-anchor" href="#configuring-resource-groups-for-pl-container" aria-label="Permalink to &quot;&lt;a id=&quot;topic_resgroupcfg&quot;&gt;&lt;/a&gt;Configuring Resource Groups for PL/Container&quot;">​</a></h3><p>To use WarehousePG resource groups to manage PL/Container resources, you must explicitly configure both resource groups and PL/Container.</p><p>Perform the following procedure to configure PL/Container to use WarehousePG resource groups for CPU resource management:</p><ol><li><p>Analyze the resource usage of your WarehousePG deployment. Determine the percentage of resource group CPU resources that you want to allocate to PL/Container Docker containers.</p></li><li><p>Determine how you want to distribute the total PL/Container CPU resources that you identified in the step above among the PL/Container runtimes. Identify:</p><ul><li>The number of PL/Container resource group(s) that you require.</li><li>The percentage of CPU resources to allocate to each resource group.</li><li>The resource-group-to-PL/Container-runtime assignment(s).</li></ul></li><li><p>Create the PL/Container resource groups that you identified in the step above. For example, suppose that you choose to allocate 25% of CPU WarehousePG resources to PL/Container. If you further split these resources among two resource groups 60/40, the following SQL commands create the resource groups:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>CREATE RESOURCE GROUP plr_run1_rg WITH (CONCURRENCY=0, CPU_MAX_PERCENT=15);</span></span>
<span class="line"><span>CREATE RESOURCE GROUP plpy_run1_rg WITH (CONCURRENCY=0, CPU_MAX_PERCENT=10);</span></span></code></pre></div></li><li><p>Find and note the <code>groupid</code> associated with each resource group that you created. For example:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>SELECT groupname, groupid FROM gp_toolkit.gp_resgroup_config</span></span>
<span class="line"><span>WHERE groupname IN (&#39;plpy_run1_rg&#39;, &#39;plr_run1_rg&#39;);</span></span>
<span class="line"><span>                                    </span></span>
<span class="line"><span>groupname   |  groupid</span></span>
<span class="line"><span>--------------+----------</span></span>
<span class="line"><span>plpy_run1_rg |   16391</span></span>
<span class="line"><span>plr_run1_rg  |   16393</span></span>
<span class="line"><span>(1 row)</span></span></code></pre></div></li><li><p>Assign each resource group that you created to the desired PL/Container runtime configuration. If you have not yet created the runtime configuration, use the <code>plcontainer runtime-add</code> command. If the runtime already exists, use the <code>plcontainer runtime-replace</code> or <code>plcontainer runtime-edit</code> command to add the resource group assignment to the runtime configuration. For example:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>plcontainer runtime-add -r python_run1 -i pivotaldata/plcontainer_python_shared:devel -l python -s resource_group_id=16391</span></span>
<span class="line"><span>plcontainer runtime-replace -r r_run1 -i pivotaldata/plcontainer_r_shared:devel -l r -s resource_group_id=16393</span></span></code></pre></div><p>For information about the <code>plcontainer</code> command, see <a href="./../utility_guide/ref/plcontainer.html">plcontainer</a> reference page.</p></li></ol><h3 id="using-resource-groups-to-manage-pl-container-resources" tabindex="-1"><a id="topic_resgroup"></a>Using Resource Groups to Manage PL/Container Resources <a class="header-anchor" href="#using-resource-groups-to-manage-pl-container-resources" aria-label="Permalink to &quot;&lt;a id=&quot;topic_resgroup&quot;&gt;&lt;/a&gt;Using Resource Groups to Manage PL/Container Resources&quot;">​</a></h3><p>With PL/Container 2.4.0 and later, you can use WarehousePG resource groups to manage and limit the total CPU resources of containers in PL/Container runtimes. For more information about enabling, configuring, and using WarehousePG resource groups, refer to <a href="./../admin_guide/workload_mgmt_resgroups.html">Using Resource Groups</a> in the <em>WarehousePG Administrator Guide</em>.</p><blockquote><p><strong>Note</strong> If you do not explicitly configure resource groups for a PL/Container runtime, its container instances are limited only by system resources. The containers may consume resources at the expense of the WarehousePG server.</p></blockquote><h2 id="pl-container-logging" tabindex="-1"><a id="plc_notes"></a>PL/Container Logging <a class="header-anchor" href="#pl-container-logging" aria-label="Permalink to &quot;&lt;a id=&quot;plc_notes&quot;&gt;&lt;/a&gt;PL/Container Logging&quot;">​</a></h2><p>When PL/Container logging is enabled, you can set the log level with the WarehousePG server configuration parameter <a href="./../ref_guide/config_params/guc-list.html">log_min_messages</a>. The default log level is <code>warning</code>. The parameter controls the PL/Container log level and also controls the WarehousePG log level.</p><ul><li><p>PL/Container logging is enabled or deactivated for each runtime ID with the <code>setting</code> attribute <code>use_container_logging</code>. The default is no logging.</p></li><li><p>The PL/Container log information is the information from the UDF that is run in the Docker container. By default, the PL/Container log information is sent to a system service. On Red Hat 8 systems, the log information is sent to the <code>journald</code> service.</p></li><li><p>The WarehousePG log information is sent to log file on the WarehousePG coordinator.</p></li><li><p>When testing or troubleshooting a PL/Container UDF, you can change the WarehousePG log level with the <code>SET</code> command. You can set the parameter in the session before you run your PL/Container UDF. This example sets the log level to <code>debug1</code>.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>SET log_min_messages=&#39;debug1&#39; ;</span></span></code></pre></div><blockquote><p><strong>Note</strong> The parameter <code>log_min_messages</code> controls both the WarehousePG and PL/Container logging, increasing the log level might affect WarehousePG performance even if a PL/Container UDF is not running.</p></blockquote></li></ul><h2 id="pl-container-function-limitations" tabindex="-1"><a id="topic_rh3_p3q_dw"></a>PL/Container Function Limitations <a class="header-anchor" href="#pl-container-function-limitations" aria-label="Permalink to &quot;&lt;a id=&quot;topic_rh3_p3q_dw&quot;&gt;&lt;/a&gt;PL/Container Function Limitations&quot;">​</a></h2><p>Review the following limitations when creating and using PL/Container PL/Python and PL/R functions:</p><ul><li>WarehousePG domains are not supported.</li><li>Multi-dimensional arrays are not supported.</li><li>Python and R call stack information is not displayed when debugging a UDF.</li><li>The <code>plpy.execute()</code> methods <code>nrows()</code> and <code>status()</code> are not supported.</li><li>The PL/Python function <code>plpy.SPIError()</code> is not supported.</li><li>Running the <code>SAVEPOINT</code> command with <code>plpy.execute()</code> is not supported.</li><li>Container flow control is not supported.</li><li>Triggers are not supported.</li><li><code>OUT</code> parameters are not supported.</li><li>The Python <code>dict</code> type cannot be returned from a PL/Python UDF. When returning the Python <code>dict</code> type from a UDF, you can convert the <code>dict</code> type to a WarehousePG user-defined data type (UDT).</li></ul><h2 id="developing-pl-container-functions" tabindex="-1"><a id="using_functions"></a>Developing PL/Container functions <a class="header-anchor" href="#developing-pl-container-functions" aria-label="Permalink to &quot;&lt;a id=&quot;using_functions&quot;&gt;&lt;/a&gt;Developing PL/Container functions&quot;">​</a></h2><p>When you enable PL/Container in a database of a WarehousePG cluster, the language <code>plcontainer</code> is registered in that database. Specify <code>plcontainer</code> as a language in a UDF definition to create and run user-defined functions in the procedural languages supported by the PL/Container Docker images.</p><p>A UDF definition that uses PL/Container must have these items.</p><ul><li>The first line of the UDF must be <code># container: ID</code></li><li>The <code>LANGUAGE</code> attribute must be <code>plcontainer</code></li></ul><p>The ID is the name that PL/Container uses to identify a Docker image. When WarehousePG runs a UDF on a host, the Docker image on the host is used to start a Docker container that runs the UDF. In the XML configuration file <code>plcontainer_configuration.xml</code>, there is a <code>runtime</code> XML element that contains a corresponding <code>id</code> XML element that specifies the Docker container startup information. See <a href="./../utility_guide/ref/plcontainer-configuration.html">plcontainer Configuration File</a> for information about how PL/Container maps the ID to a Docker image.</p><p>The PL/Container configuration file is read only on the first invocation of a PL/Container function in each WarehousePG session that runs PL/Container functions. You can force the configuration file to be re-read by performing a <code>SELECT</code> command on the view <code>plcontainer_refresh_config</code> during the session. For example, this <code>SELECT</code> command forces the configuration file to be read.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>SELECT * FROM plcontainer_refresh_config;</span></span></code></pre></div><p>The command runs a PL/Container function that updates the configuration on the coordinator and segment instances and returns the status of the refresh.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span> gp_segment_id | plcontainer_refresh_local_config</span></span>
<span class="line"><span> ---------------+----------------------------------</span></span>
<span class="line"><span> 1 | ok</span></span>
<span class="line"><span> 0 | ok</span></span>
<span class="line"><span>-1 | ok</span></span>
<span class="line"><span>(3 rows)</span></span></code></pre></div><p>Also, you can show all the configurations in the session by performing a <code>SELECT</code> command on the view <code>plcontainer_show_config</code>. For example, this <code>SELECT</code> command returns the PL/Container configurations.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>SELECT * FROM plcontainer_show_config;</span></span></code></pre></div><p>Running the command executes a PL/Container function that displays configuration information from the coordinator and segment instances. This is an example of the start and end of the view output.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>INFO:  plcontainer: Container &#39;plc_py_test&#39; configuration</span></span>
<span class="line"><span> INFO:  plcontainer:     image = &#39;pivotaldata/plcontainer_python_shared:devel&#39;</span></span>
<span class="line"><span> INFO:  plcontainer:     memory_mb = &#39;1024&#39;</span></span>
<span class="line"><span> INFO:  plcontainer:     use container network = &#39;no&#39;</span></span>
<span class="line"><span> INFO:  plcontainer:     use container logging  = &#39;no&#39;</span></span>
<span class="line"><span> INFO:  plcontainer:     shared directory from host &#39;/usr/local/greenplum-db/./bin/plcontainer_clients&#39; to container &#39;/clientdir&#39;</span></span>
<span class="line"><span> INFO:  plcontainer:     access = readonly</span></span>
<span class="line"><span>                </span></span>
<span class="line"><span> ...</span></span>
<span class="line"><span>                </span></span>
<span class="line"><span> INFO:  plcontainer: Container &#39;plc_r_example&#39; configuration  (seg0 slice3 192.168.180.45:40000 pid=3304)</span></span>
<span class="line"><span> INFO:  plcontainer:     image = &#39;pivotaldata/plcontainer_r_without_clients:0.2&#39;  (seg0 slice3 192.168.180.45:40000 pid=3304)</span></span>
<span class="line"><span> INFO:  plcontainer:     memory_mb = &#39;1024&#39;  (seg0 slice3 192.168.180.45:40000 pid=3304)</span></span>
<span class="line"><span> INFO:  plcontainer:     use container network = &#39;no&#39;  (seg0 slice3 192.168.180.45:40000 pid=3304)</span></span>
<span class="line"><span> INFO:  plcontainer:     use container logging  = &#39;yes&#39;  (seg0 slice3 192.168.180.45:40000 pid=3304)</span></span>
<span class="line"><span> INFO:  plcontainer:     shared directory from host &#39;/usr/local/greenplum-db/bin/plcontainer_clients&#39; to container &#39;/clientdir&#39;  (seg0 slice3 192.168.180.45:40000 pid=3304)</span></span>
<span class="line"><span> INFO:  plcontainer:         access = readonly  (seg0 slice3 192.168.180.45:40000 pid=3304)</span></span>
<span class="line"><span> gp_segment_id | plcontainer_show_local_config</span></span>
<span class="line"><span> ---------------+-------------------------------</span></span>
<span class="line"><span>  0 | ok</span></span>
<span class="line"><span> -1 | ok</span></span>
<span class="line"><span>  1 | ok</span></span></code></pre></div><p>The PL/Container function <code>plcontainer_containers_summary()</code> displays information about the currently running Docker containers.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>SELECT * FROM plcontainer_containers_summary();</span></span></code></pre></div><p>If a normal (non-superuser) WarehousePG user runs the function, the function displays information only for containers created by the user. If a WarehousePG superuser runs the function, information for all containers created by WarehousePG users is displayed. This is sample output when 2 containers are running.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span> SEGMENT_ID |                           CONTAINER_ID                           |   UP_TIME    |  OWNER  | MEMORY_USAGE(KB)</span></span>
<span class="line"><span> ------------+------------------------------------------------------------------+--------------+---------+------------------</span></span>
<span class="line"><span> 1          | 693a6cb691f1d2881ec0160a44dae2547a0d5b799875d4ec106c09c97da422ea | Up 8 seconds | gpadmin | 12940</span></span>
<span class="line"><span> 1          | bc9a0c04019c266f6d8269ffe35769d118bfb96ec634549b2b1bd2401ea20158 | Up 2 minutes | gpadmin | 13628</span></span>
<span class="line"><span> (2 rows)</span></span></code></pre></div><p>When WarehousePG runs a PL/Container UDF, Query Executer (QE) processes start Docker containers and reuse them as needed. After a certain amount of idle time, a QE process quits and destroys its Docker containers. You can control the amount of idle time with the WarehousePG server configuration parameter <a href="./../ref_guide/config_params/guc-list.html">gp_vmem_idle_resource_timeout</a>. Controlling the idle time might help with Docker container reuse and avoid the overhead of creating and starting a Docker container.</p><blockquote><p><strong>Caution</strong> Changing <code>gp_vmem_idle_resource_timeout</code> value, might affect performance due to resource issues. The parameter also controls the freeing of WarehousePG resources other than Docker containers.</p></blockquote><h3 id="basic-function-examples" tabindex="-1"><a id="function_examples"></a>Basic Function Examples <a class="header-anchor" href="#basic-function-examples" aria-label="Permalink to &quot;&lt;a id=&quot;function_examples&quot;&gt;&lt;/a&gt;Basic Function Examples&quot;">​</a></h3><p>The values in the <code># container</code> lines of the examples, <code>plc_python_shared</code> and <code>plc_r_shared</code>, are the <code>id</code> XML elements defined in the <code>plcontainer_config.xml</code> file. The <code>id</code> element is mapped to the <code>image</code> element that specifies the Docker image to be started. If you configured PL/Container with a different ID, change the value of the <code># container</code> line. For information about configuring PL/Container and viewing the configuration settings, see <a href="./../utility_guide/ref/plcontainer-configuration.html">plcontainer Configuration File</a>.</p><p>This is an example of PL/Python function that runs using the <code>plc_python_shared</code> container that contains Python 2:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>CREATE OR REPLACE FUNCTION pylog100() RETURNS double precision AS $$</span></span>
<span class="line"><span> # container: plc_python_shared</span></span>
<span class="line"><span> import math</span></span>
<span class="line"><span> return math.log10(100)</span></span>
<span class="line"><span> $$ LANGUAGE plcontainer;</span></span></code></pre></div><p>This is an example of a similar function using the <code>plc_r_shared</code> container:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>CREATE OR REPLACE FUNCTION rlog100() RETURNS text AS $$</span></span>
<span class="line"><span># container: plc_r_shared</span></span>
<span class="line"><span>return(log10(100))</span></span>
<span class="line"><span>$$ LANGUAGE plcontainer;</span></span></code></pre></div><p>If the <code># container</code> line in a UDF specifies an ID that is not in the PL/Container configuration file, WarehousePG returns an error when you try to run the UDF.</p><h3 id="about-pl-python-2-functions-in-pl-container" tabindex="-1"><a id="topic_ctk_xjg_wkb"></a>About PL/Python 2 Functions in PL/Container <a class="header-anchor" href="#about-pl-python-2-functions-in-pl-container" aria-label="Permalink to &quot;&lt;a id=&quot;topic_ctk_xjg_wkb&quot;&gt;&lt;/a&gt;About PL/Python 2 Functions in PL/Container&quot;">​</a></h3><p>In the Python 2 language container, the module <code>plpy</code> is implemented. The module contains these methods:</p><ul><li><code>plpy.execute(stmt)</code> - Runs the query string <code>stmt</code> and returns query result in a list of dictionary objects. To be able to access the result fields ensure your query returns named fields.</li><li><code>plpy.prepare(stmt[, argtypes])</code> - Prepares the execution plan for a query. It is called with a query string and a list of parameter types, if you have parameter references in the query.</li><li><code>plpy.execute(plan[, argtypes])</code> - Runs a prepared plan.</li><li><code>plpy.debug(msg)</code> - Sends a DEBUG2 message to the WarehousePG log.</li><li><code>plpy.log(msg)</code> - Sends a LOG message to the WarehousePG log.</li><li><code>plpy.info(msg)</code> - Sends an INFO message to the WarehousePG log.</li><li><code>plpy.notice(msg)</code> - Sends a NOTICE message to the WarehousePG log.</li><li><code>plpy.warning(msg)</code> - Sends a WARNING message to the WarehousePG log.</li><li><code>plpy.error(msg)</code> - Sends an ERROR message to the WarehousePG log. An ERROR message raised in WarehousePG causes the query execution process to stop and the transaction to rollback.</li><li><code>plpy.fatal(msg)</code> - Sends a FATAL message to the WarehousePG log. A FATAL message causes WarehousePG session to be closed and transaction to be rolled back.</li><li><code>plpy.subtransaction()</code> - Manages <code>plpy.execute</code> calls in an explicit subtransaction. See <a href="https://www.postgresql.org/docs/12/plpython-subtransaction.html" target="_blank" rel="noreferrer">Explicit Subtransactions</a> in the PostgreSQL documentation for additional information about <code>plpy.subtransaction()</code>.</li></ul><p>If an error of level <code>ERROR</code> or <code>FATAL</code> is raised in a nested Python function call, the message includes the list of enclosing functions.</p><p>The Python language container supports these string quoting functions that are useful when constructing ad-hoc queries.</p><ul><li><code>plpy.quote_literal(string)</code> - Returns the string quoted to be used as a string literal in an SQL statement string. Embedded single-quotes and backslashes are properly doubled. <code>quote_literal()</code> returns null on null input (empty input). If the argument might be null, <code>quote_nullable()</code> might be more appropriate.</li><li><code>plpy.quote_nullable(string)</code> - Returns the string quoted to be used as a string literal in an SQL statement string. If the argument is null, returns <code>NULL</code>. Embedded single-quotes and backslashes are properly doubled.</li><li><code>plpy.quote_ident(string)</code> - Returns the string quoted to be used as an identifier in an SQL statement string. Quotes are added only if necessary (for example, if the string contains non-identifier characters or would be case-folded). Embedded quotes are properly doubled.</li></ul><p>When returning text from a PL/Python function, PL/Container converts a Python unicode object to text in the database encoding. If the conversion cannot be performed, an error is returned.</p><p>PL/Container does not support this WarehousePG PL/Python feature:</p><ul><li>Multi-dimensional arrays.</li></ul><p>Also, the Python module has two global dictionary objects that retain the data between function calls. They are named GD and SD. GD is used to share the data between all the function running within the same container, while SD is used for sharing the data between multiple calls of each separate function. Be aware that accessing the data is possible only within the same session, when the container process lives on a segment or coordinator. Be aware that for idle sessions WarehousePG terminates segment processes, which means the related containers would be shut down and the data from GD and SD lost.</p><p>For information about PL/Python, see <a href="./pl_python.html">PL/Python Language</a>.</p><p>For information about the <code>plpy</code> methods, see <a href="https://www.postgresql.org/docs/12/plpython-database.html" target="_blank" rel="noreferrer">https://www.postgresql.org/docs/12/plpython-database.htm</a>.</p><h3 id="about-pl-python-3-functions-in-pl-container" tabindex="-1"><a id="topic_plc_py3"></a>About PL/Python 3 Functions in PL/Container <a class="header-anchor" href="#about-pl-python-3-functions-in-pl-container" aria-label="Permalink to &quot;&lt;a id=&quot;topic_plc_py3&quot;&gt;&lt;/a&gt;About PL/Python 3 Functions in PL/Container&quot;">​</a></h3><p>PL/Container for WarehousePG 5 supports Python version 3.6+. PL/Container for WarehousePG 6 supports Python 3.7+.</p><p>If you want to use PL/Container to run the same function body in both Python2 and Python3, you must create 2 different user-defined functions.</p><p>Keep in mind that UDFs that you created for Python 2 may not run in PL/Container with Python 3. The following Python references may be useful:</p><ul><li>Changes to Python - <a href="https://docs.python.org/3/whatsnew/3.0.html" target="_blank" rel="noreferrer">What’s New in Python 3</a></li><li>Porting from Python 2 to 3 - <a href="https://docs.python.org/3/howto/pyporting.html" target="_blank" rel="noreferrer">Porting Python 2 Code to Python 3</a></li></ul><h3 id="developing-cuda-api-functions-with-pl-container" tabindex="-1"><a id="cuda"></a>Developing CUDA API Functions with PL/Container <a class="header-anchor" href="#developing-cuda-api-functions-with-pl-container" aria-label="Permalink to &quot;&lt;a id=&quot;cuda&quot;&gt;&lt;/a&gt;Developing CUDA API Functions with PL/Container&quot;">​</a></h3><p>Beginning with version 2.2, PL/Container supports developing Compute Unified Device Architecture (CUDA) API functions that utilize NVIDIA GPU hardware. This is accomplished by using the NVIDIA Container Toolkit <code>nvidia-docker</code> image and the <code>pycuda</code> python library. This procedure explains how to set up PL/Container for developing these functions.</p><h4 id="prerequisites" tabindex="-1">Prerequisites <a class="header-anchor" href="#prerequisites" aria-label="Permalink to &quot;Prerequisites&quot;">​</a></h4><p>To develop CUDA functions with PL/Container you require:</p><ul><li>A Docker installation having Docker engine version v19.03 or newer</li><li>PL/Container version 2.2.0 or newer</li><li>At least one NVIDIA GPU with the required GPU driver installed on your host</li></ul><p>See the <a href="https://github.com/NVIDIA/nvidia-docker" target="_blank" rel="noreferrer">Getting Started</a> section of the NVIDIA Container Toolkit GitHub project for information about installing the NVIDIA driver or Docker engine for your Linux distribution.</p><p>Follow the <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html" target="_blank" rel="noreferrer">Installation Guide</a> for the NVIDIA Container Toolkit GitHub project to install the <code>nvidia-docker</code> container.</p><p>Verify that the Docker image can use your installed GPU(s) by running a command similar to:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>$ docker run --rm --gpus=all -it nvidia/cuda:11.7.0-devel-ubuntu20.04 nvidia-smi –L</span></span></code></pre></div><p>(Substitute the actual <code>nvidia-docker</code> image name and tag that you installed.) The command output should show that GPU hardware is utilized. For example:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>GPU 0: NVIDIA GeForce RTX 2070 (UUID: GPU-d4d626a3-bbc9-ef88-98dc-44423ad081bf)</span></span></code></pre></div><p>Record the name of the GPU device ID (0 in the above example) or the device UUID (GPU-d4d626a3-bbc9-ef88-98dc-44423ad081bf) that you want to assign to the PL/Container image.</p><h4 id="install-and-customize-the-pl-container-image" tabindex="-1">Install and Customize the PL/Container Image <a class="header-anchor" href="#install-and-customize-the-pl-container-image" aria-label="Permalink to &quot;Install and Customize the PL/Container Image&quot;">​</a></h4><ol><li><p>Download PL/Container from the <a href="https://github.com/warehouse-pg" target="_blank" rel="noreferrer">WarehousePG Github Org</a>.</p></li><li><p>Load the downloaded PL/Container image into Docker:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>$ docker image load &lt; plcontainer-python3-image-2.2.0-gp7.tar.gz</span></span></code></pre></div></li><li><p>Customize the PL/Container image to add the required CUDA runtime and <code>pycuda</code> library. The following example Dockerfile contents show how to add CUDA 11.7 and <code>pycuda</code> 2021.1 to the PL/Container image. Use a text editor to create the Dockerfile:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>FROM pivotaldata/plcontainer_python3_shared:devel </span></span>
<span class="line"><span></span></span>
<span class="line"><span>ENV XKBLAYOUT=en </span></span>
<span class="line"><span>ENV DEBIAN_FRONTEND=noninteractive </span></span>
<span class="line"><span></span></span>
<span class="line"><span># Install CUDA from https://developer.nvidia.com/cuda-downloads </span></span>
<span class="line"><span># By downloading and using the software, you agree to fully comply with the terms and conditions of the CUDA EULA. </span></span>
<span class="line"><span>RUN true &amp;&amp;\\ </span></span>
<span class="line"><span>    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin &amp;&amp; \\ </span></span>
<span class="line"><span>    mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600 &amp;&amp; \\ </span></span>
<span class="line"><span>    wget https://developer.download.nvidia.com/compute/cuda/11.7.0/local_installers/cuda-repo-ubuntu1804-11-7-local_11.7.0-515.43.04-1_amd64.deb &amp;&amp; \\ </span></span>
<span class="line"><span>    dpkg -i cuda-repo-ubuntu1804-11-7-local_11.7.0-515.43.04-1_amd64.deb &amp;&amp; \\ </span></span>
<span class="line"><span>    cp /var/cuda-repo-ubuntu1804-11-7-local/cuda-*-keyring.gpg /usr/share/keyrings/ &amp;&amp; \\ </span></span>
<span class="line"><span>    apt-get update &amp;&amp; \\ </span></span>
<span class="line"><span>    apt-get -y install cuda &amp;&amp; \\ </span></span>
<span class="line"><span>    rm cuda-repo-ubuntu1804-11-7-local_11.7.0-515.43.04-1_amd64.deb &amp;&amp;\\ </span></span>
<span class="line"><span>    rm -rf /var/lib/apt/lists/* </span></span>
<span class="line"><span></span></span>
<span class="line"><span>ENV PATH=&quot;/usr/local/cuda-11.7/bin/:\${PATH}&quot; </span></span>
<span class="line"><span>ENV LD_LIBRARY_PATH=&quot;/usr/local/cuda-11.7/lib64:\${LD_LIBRARY_PATH:+:\${LD_LIBRARY_PATH}}&quot; </span></span>
<span class="line"><span>ENV CUDA_HOME=&quot;/usr/local/cuda-11.7&quot; </span></span>
<span class="line"><span></span></span>
<span class="line"><span>RUN true &amp;&amp; \\ </span></span>
<span class="line"><span>    python3.7 -m pip --no-cache-dir install typing-extensions==3.10.0.0 &amp;&amp; \\ </span></span>
<span class="line"><span>    python3.7 -m pip --no-cache-dir install Mako==1.2.0 &amp;&amp; \\ </span></span>
<span class="line"><span>    python3.7 -m pip --no-cache-dir install platformdirs==2.5.2 &amp;&amp; \\ </span></span>
<span class="line"><span>    python3.7 -m pip --no-cache-dir install pytools==2022.1.2 &amp;&amp; \\ </span></span>
<span class="line"><span>    python3.7 -m pip --no-cache-dir install pycuda==2021.1</span></span></code></pre></div></li><li><p>Build the a customized container using your Dockerfile:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>$ docker build . -t localhost/plcontainer_python3_cuda_shared:latest</span></span></code></pre></div><blockquote><p><strong>Note</strong> The remaining instructions use the example image tag <code>localhost/plcontainer_python3_cuda_shared:latest</code>. Substitute the actual tag name as needed.</p></blockquote></li><li><p>Import the image runtime to PL/Container:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>$ plcontainer runtime-add -r plc_python_cuda_shared -I localhost/plcontainer_python3_cuda_shared:latest -l python3</span></span></code></pre></div></li><li><p>Edit the image runtime to assign a GPU. The following example adds GPU device ID <code>0</code> as the GPU, and <code>gpadmin</code> as the designated role. Substitute either the GPU device ID or the device UUID that you recorded earlier:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>$ plcontainer runtime-edit</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>&lt;runtime&gt; </span></span>
<span class="line"><span>    &lt;id&gt;plc_python_cuda_shared&lt;/id&gt; </span></span>
<span class="line"><span>    &lt;image&gt;localhost/plcontainer_python3_cuda_shared:latest&lt;/image&gt; </span></span>
<span class="line"><span>    &lt;command&gt;/clientdir/py3client.sh&lt;/command&gt; </span></span>
<span class="line"><span>    &lt;setting roles=&quot;gpadmin&quot;/&gt; </span></span>
<span class="line"><span>    &lt;shared_directory access=&quot;ro&quot; container=&quot;/clientdir&quot; host=&quot;/usr/local/greenplum-db/bin/plcontainer_clients&quot;/&gt; </span></span>
<span class="line"><span>    &lt;device_request type=&quot;gpu&quot;&gt; </span></span>
<span class="line"><span>        &lt;deviceid&gt;0&lt;/deviceid&gt; </span></span>
<span class="line"><span>    &lt;/device_request&gt; </span></span>
<span class="line"><span>&lt;/runtime&gt;</span></span></code></pre></div></li></ol><h4 id="create-and-run-a-sample-cuda-function" tabindex="-1">Create and Run a Sample CUDA Function <a class="header-anchor" href="#create-and-run-a-sample-cuda-function" aria-label="Permalink to &quot;Create and Run a Sample CUDA Function&quot;">​</a></h4><ol><li><p>Connect to a WarehousePG where PL/Container is installed:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>$ psql -d mytest -h coordinator_host -p 5432 -U \`gpadmin\`</span></span></code></pre></div></li><li><p>Create a sample PL/Container function that uses the container you customized (<code>plc_python_cuda_shared</code> in this example). This simple function multiplies randomized, single-precision numbers by sending them to the CUDA constructor of <code>pycuda.compiler.SourceModule</code>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>CREATE FUNCTION hello_cuda() RETURNS float4[] AS $$ </span></span>
<span class="line"><span># container: plc_python_cuda_shared </span></span>
<span class="line"><span></span></span>
<span class="line"><span>import pycuda.driver as drv </span></span>
<span class="line"><span>import pycuda.tools </span></span>
<span class="line"><span>import pycuda.autoinit </span></span>
<span class="line"><span>import numpy </span></span>
<span class="line"><span>import numpy.linalg as la </span></span>
<span class="line"><span>from pycuda.compiler import SourceModule </span></span>
<span class="line"><span></span></span>
<span class="line"><span>mod = SourceModule(&quot;&quot;&quot; </span></span>
<span class="line"><span>__global__ void multiply_them(float *dest, float *a, float *b) </span></span>
<span class="line"><span>{ </span></span>
<span class="line"><span>  const int i = threadIdx.x; </span></span>
<span class="line"><span>  dest[i] = a[i] * b[i]; </span></span>
<span class="line"><span>} </span></span>
<span class="line"><span>&quot;&quot;&quot;) </span></span>
<span class="line"><span></span></span>
<span class="line"><span>multiply_them = mod.get_function(&quot;multiply_them&quot;) </span></span>
<span class="line"><span>  </span></span>
<span class="line"><span>a = numpy.random.randn(400).astype(numpy.float32) </span></span>
<span class="line"><span>b = numpy.random.randn(400).astype(numpy.float32) </span></span>
<span class="line"><span></span></span>
<span class="line"><span>dest = numpy.zeros_like(a) </span></span>
<span class="line"><span>multiply_them( </span></span>
<span class="line"><span>        drv.Out(dest), drv.In(a), drv.In(b), </span></span>
<span class="line"><span>        block=(400,1,1)) </span></span>
<span class="line"><span>  </span></span>
<span class="line"><span>return [float(i) for i in (dest-a*b)] </span></span>
<span class="line"><span></span></span>
<span class="line"><span>$$ LANGUAGE plcontainer;</span></span></code></pre></div></li><li><p>Run the sample function and verify its output:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>$ WITH a AS (SELECT unnest(hello) AS cuda FROM hello_cuda() AS hello) SELECT sum(cuda) FROM a;</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>psql&gt;   +-----+ </span></span>
<span class="line"><span>psql&gt;   | sum | </span></span>
<span class="line"><span>psql&gt;   |-----| </span></span>
<span class="line"><span>psql&gt;   | 0.0 | </span></span>
<span class="line"><span>psql&gt;   +-----+ </span></span>
<span class="line"><span>psql&gt;   SELECT 1 </span></span>
<span class="line"><span>psql&gt;   Time: 0.012s</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>$ SELECT * FROM hello_cuda();</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>psql&gt;   +-----------------------+ </span></span>
<span class="line"><span>psql&gt;   |       hello_cuda      | </span></span>
<span class="line"><span>psql&gt;   |-----------------------| </span></span>
<span class="line"><span>psql&gt;   | {0, 0.... many 0 ...} | </span></span>
<span class="line"><span>psql&gt;   +-----------------------+ </span></span>
<span class="line"><span>psql&gt;   SELECT 1 </span></span>
<span class="line"><span>psql&gt;   Time: 0.012s</span></span></code></pre></div></li></ol><h3 id="about-pl-r-functions-in-pl-container" tabindex="-1"><a id="topic_lqz_t3q_dw"></a>About PL/R Functions in PL/Container <a class="header-anchor" href="#about-pl-r-functions-in-pl-container" aria-label="Permalink to &quot;&lt;a id=&quot;topic_lqz_t3q_dw&quot;&gt;&lt;/a&gt;About PL/R Functions in PL/Container&quot;">​</a></h3><p>In the R language container, the module <code>pg.spi</code> is implemented. The module contains these methods:</p><ul><li><code>pg.spi.exec(stmt)</code> - Runs the query string <code>stmt</code> and returns query result in R <code>data.frame</code>. To be able to access the result fields make sure your query returns named fields.</li><li><code>pg.spi.prepare(stmt[, argtypes])</code> - Prepares the execution plan for a query. It is called with a query string and a list of parameter types if you have parameter references in the query.</li><li><code>pg.spi.execp(plan[, argtypes])</code> - Runs a prepared plan.</li><li><code>pg.spi.debug(msg)</code> - Sends a DEBUG2 message to the WarehousePG log.</li><li><code>pg.spi.log(msg)</code> - Sends a LOG message to the WarehousePG log.</li><li><code>pg.spi.info(msg)</code> - Sends an INFO message to the WarehousePG log.</li><li><code>pg.spi.notice(msg)</code> - Sends a NOTICE message to the WarehousePG log.</li><li><code>pg.spi.warning(msg)</code> - Sends a WARNING message to the WarehousePG log.</li><li><code>pg.spi.error(msg)</code> - Sends an ERROR message to the WarehousePG log. An ERROR message raised in WarehousePG causes the query execution process to stop and the transaction to rollback.</li><li><code>pg.spi.fatal(msg)</code> - Sends a FATAL message to the WarehousePG log. A FATAL message causes WarehousePG session to be closed and transaction to be rolled back.</li></ul><p>PL/Container does not support this PL/R feature:</p><ul><li>Multi-dimensional arrays.</li></ul><p>For information about PL/R, see <a href="./pl_r.html">PL/R Language</a>.</p><p>For information about the <code>pg.spi</code> methods, see <a href="http://www.joeconway.com/plr/doc/plr-spi-rsupport-funcs-normal.html" target="_blank" rel="noreferrer">http://www.joeconway.com/plr/doc/plr-spi-rsupport-funcs-normal.html</a></p><h2 id="configuring-a-remote-pl-container" tabindex="-1"><a id="remote_container"></a>Configuring a Remote PL/Container <a class="header-anchor" href="#configuring-a-remote-pl-container" aria-label="Permalink to &quot;&lt;a id=&quot;remote_container&quot;&gt;&lt;/a&gt;Configuring a Remote PL/Container&quot;">​</a></h2><p>You may configure one or more hosts outside your WarehousePG cluster to use as a remote container host. The PL/Container workload can be dispatched to this host for execution and it will return the results, reducing the computing overload of the WarehousePG hosts.</p><h3 id="prerequisites-1" tabindex="-1"><a id="prereq"></a>Prerequisites <a class="header-anchor" href="#prerequisites-1" aria-label="Permalink to &quot;&lt;a id=&quot;prereq&quot;&gt;&lt;/a&gt;Prerequisites&quot;">​</a></h3><ul><li>You are using PL/Container version 2.4.0.</li><li>You are using a Docker installation with a Docker engine version v19.03 or newer.</li><li>You have root or sudo permission on the remote host.</li></ul><h3 id="configure-the-remote-host" tabindex="-1"><a id="setup_host"></a>Configure the Remote Host <a class="header-anchor" href="#configure-the-remote-host" aria-label="Permalink to &quot;&lt;a id=&quot;setup_host&quot;&gt;&lt;/a&gt;Configure the Remote Host&quot;">​</a></h3><p>Install docker on the remote host. This step may vary depending on your operating system. For example, for RHEL 7:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>sudo yum install -y yum-utils </span></span>
<span class="line"><span>sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo </span></span>
<span class="line"><span>sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin </span></span>
<span class="line"><span>sudo systemctl enable  --now docker</span></span></code></pre></div><p>Enable the remote API for Docker:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>sudo systemctl edit docker.service </span></span>
<span class="line"><span></span></span>
<span class="line"><span># add the following to the start of the file:</span></span>
<span class="line"><span> </span></span>
<span class="line"><span>[Service] </span></span>
<span class="line"><span>ExecStart= </span></span>
<span class="line"><span>ExecStart=/usr/bin/dockerd -H fd:// -H tcp://0.0.0.0:2375 </span></span>
<span class="line"><span></span></span>
<span class="line"><span># restart docker service </span></span>
<span class="line"><span></span></span>
<span class="line"><span>sudo systemctl restart docker</span></span></code></pre></div><p>Set up the remote host. This example assumes that you have created the <code>gpadmin</code> user, enabled password-less ssh access, and that <code>python3</code> and <code>rsync</code> are installed in the remote host.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>ssh gpadmin@&lt;remoteip&gt; &quot;sudo mkdir $GPHOME &amp;&amp; sudo chown gpadmin:gpadmin $GPHOME&quot;</span></span></code></pre></div><p>From the WarehousePG coordinator, copy the <code>plcontainer</code> client to the remote host.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>plcontainer remote-setup --hosts &lt;remoteip&gt;</span></span></code></pre></div><p>If you are configuring multiple hosts, you may run the command against multiple remote hosts:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>plcontainer remote-setup --hosts &lt;remoteip_1&gt;, &lt;remoteip_2&gt;, &lt;remoteip_3&gt;</span></span></code></pre></div><h3 id="load-the-docker-image-to-the-remote-host" tabindex="-1"><a id="loading"></a>Load the Docker Image to the Remote Host <a class="header-anchor" href="#load-the-docker-image-to-the-remote-host" aria-label="Permalink to &quot;&lt;a id=&quot;loading&quot;&gt;&lt;/a&gt;Load the Docker Image to the Remote Host&quot;">​</a></h3><p>From the coordinator host, load the Docker image into the remote host. You may run the command against multiple remote hosts:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>plcontainer image-add --hosts &lt;remoteip_1&gt;, &lt;remoteip_2&gt;, &lt;remoteip_3&gt; -f &lt;image_file&gt;</span></span></code></pre></div><h3 id="configure-a-backend-node" tabindex="-1"><a id="backend"></a>Configure a Backend Node <a class="header-anchor" href="#configure-a-backend-node" aria-label="Permalink to &quot;&lt;a id=&quot;backend&quot;&gt;&lt;/a&gt;Configure a Backend Node&quot;">​</a></h3><p>Run the following command from the coordinator host:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>plcontainer runtime-edit</span></span></code></pre></div><p>This command provides the PL/Container configuration XML file. Add the backend section, as depicted in the below example, specifying the remote host IP address and port. Then edit the existing runtime section to use the newly added backend.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>&lt;?xml version=&quot;1.0&quot; ?&gt; </span></span>
<span class="line"><span>&lt;configuration&gt; </span></span>
<span class="line"><span>	&lt;backend name=&quot;calculate_cluster&quot; type=&quot;remote_docker&quot;&gt; </span></span>
<span class="line"><span>		&lt;address&gt;{THE REMOTE ADDRESS}&lt;/address&gt; </span></span>
<span class="line"><span>		&lt;port&gt;2375&lt;/port&gt; </span></span>
<span class="line"><span>	&lt;/backend&gt; </span></span>
<span class="line"><span>	&lt;runtime&gt; </span></span>
<span class="line"><span>		&lt;id&gt;plc_python_cuda_shared&lt;/id&gt; </span></span>
<span class="line"><span>		&lt;image&gt;localhost/plcontainer_python3_cuda_shared:latest&lt;/image&gt; </span></span>
<span class="line"><span>		&lt;command&gt;/clientdir/py3client.sh&lt;/command&gt; </span></span>
<span class="line"><span>		&lt;shared_directory access=&quot;ro&quot; container=&quot;/clientdir&quot; host=&quot;/home/sa/GPDB/install/bin/plcontainer_clients&quot;/&gt; </span></span>
<span class="line"><span>		&lt;backend name=&quot;calculate_cluster&quot; /&gt; </span></span>
<span class="line"><span>		&lt;setting enable_network=&quot;yes&quot; roles=&quot;gpadmin&quot; /&gt; </span></span>
<span class="line"><span>	&lt;/runtime&gt; </span></span>
<span class="line"><span>&lt;/configuration&gt;</span></span></code></pre></div><p>If you are using multiple remote hosts, you must create separate backend sections. Because you can only set one backend per runtime, you must also create a separate runtime section per backend.</p><h3 id="verify-the-configuration" tabindex="-1"><a id="verify"></a>Verify the Configuration <a class="header-anchor" href="#verify-the-configuration" aria-label="Permalink to &quot;&lt;a id=&quot;verify&quot;&gt;&lt;/a&gt;Verify the Configuration&quot;">​</a></h3><p>Run the following from the <code>psql</code> command line:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>CREATE FUNCTION dummyPython() RETURNS text AS $$ </span></span>
<span class="line"><span># container: plc_python_cuda_shared </span></span>
<span class="line"><span>return &#39;hello from Python&#39; </span></span>
<span class="line"><span>$$ LANGUAGE plcontainer; </span></span>
<span class="line"><span> </span></span>
<span class="line"><span>SELECT * from dummyPython()</span></span></code></pre></div><p>If the function runs successfully, it is running on the remote host.</p>`,123)]))}const g=n(o,[["render",i]]);export{h as __pageData,g as default};
