import{_ as r,c as i,o as s,ag as a,j as e,a as t}from"./chunks/framework.Ds6Eueu6.js";const n="/assets/gcp-disk-rates.CjDKiwoM.png",y=JSON.parse('{"title":"Platform Requirements","description":"","frontmatter":{},"headers":[],"relativePath":"docs/7x/install_guide/platform-requirements.md","filePath":"docs/7x/install_guide/platform-requirements.md"}'),l={name:"docs/7x/install_guide/platform-requirements.md"};function d(h,o,c,u,p,m){return s(),i("div",null,o[0]||(o[0]=[a(`<h1 id="platform-requirements" tabindex="-1">Platform Requirements <a class="header-anchor" href="#platform-requirements" aria-label="Permalink to &quot;Platform Requirements&quot;">​</a></h1><p>This topic describes the WarehousePG 7 platform and operating system software requirements for deploying the software to on-premise hardware, or to public cloud services such as AWS, GCP, or Azure.</p><h2 id="operating-system-requirements" tabindex="-1"><a id="operating-systems"></a>Operating System Requirements <a class="header-anchor" href="#operating-system-requirements" aria-label="Permalink to &quot;&lt;a id=&quot;operating-systems&quot;&gt;&lt;/a&gt;Operating System Requirements&quot;">​</a></h2><p>WarehousePG 7 runs on the following operating system platforms:</p><ul><li>Red Hat Enterprise Linux 64-bit 8.7 or later</li><li>Oracle Linux 64-bit 8.7 or later, using the Red Hat Compatible Kernel (RHCK)</li><li>Rocky Linux 8.7 or later</li></ul><blockquote><p><strong>Note</strong> If you use endpoint security software on your WarehousePG hosts, it may affect your database performance and stability. See <a href="./../security_guide/index.html#endpoint_security">About Endpoint Security Sofware</a> for more information.</p></blockquote><blockquote><p><strong>Caution</strong> A kernel issue in Red Hat Enterprise Linux 8.5 and 8.6 can cause I/O freezes and synchronization problems with XFS filesystems. This issue is fixed in RHEL 8.7. See <a href="https://access.redhat.com/solutions/6984334" target="_blank" rel="noreferrer">RHEL8: xfs_buf deadlock between inode deletion and block allocation</a>.</p></blockquote><p>WarehousePG server supports TLS version 1.2 on RHEL/CentOS systems, and TLS version 1.3 on Ubuntu systems.</p><h3 id="software-dependencies" tabindex="-1"><a id="topic_i4k_nlx_zgb"></a>Software Dependencies <a class="header-anchor" href="#software-dependencies" aria-label="Permalink to &quot;&lt;a id=&quot;topic_i4k_nlx_zgb&quot;&gt;&lt;/a&gt;Software Dependencies&quot;">​</a></h3><p>WarehousePG 7 requires the following software packages on RHEL systems. The packages are installed automatically as dependencies when you install the WarehousePG RPM package):</p><ul><li>apr</li><li>apr-util</li><li>bash</li><li>bzip2</li><li>curl</li><li>iproute</li><li>krb5-devel</li><li>libcgroup-tools</li><li>libcurl</li><li>libevent</li><li>libuuid</li><li>libuv</li><li>libxml2</li><li>libyaml</li><li>libzstd</li><li>openldap</li><li>openssh</li><li>openssh-client</li><li>openssh-server</li><li>openssl</li><li>openssl-libs</li><li>perl</li><li>python3</li><li>python3-psycopg2</li><li>python3-psutil</li><li>python3-pyyaml</li><li>python3.11</li><li>python3.11-devel</li><li>readline</li><li>rsync</li><li>sed</li><li>tar</li><li>which</li><li>zip</li><li>zlib</li></ul><p>WarehousePG 7 client software requires these operating system packages:</p><ul><li>apr</li><li>bzip2</li><li>libedit</li><li>libyaml</li><li>libevent</li><li>libzstd</li><li>openssh</li><li>python3</li><li>python3-psycopg2</li><li>python3-psutil</li><li>python3-pyyaml</li><li>zlib</li></ul><blockquote><p><strong>Important</strong> SSL is supported only on the WarehousePG coordinator host system. It cannot be used on the segment host systems.</p></blockquote><blockquote><p><strong>Important</strong> For all WarehousePG host systems, if SELinux is enabled in <code>Enforcing</code> mode then the WarehousePG process and users can operate successfully in the default <code>Unconfined</code> context. If increased confinement is required, then you must configure SELinux contexts, policies, and domains based on your security requirements, and test your configuration to ensure there is no functionality or performance impact to WarehousePG. Similarly, you should either deactivate or configure firewall software as needed to allow communication between WarehousePG hosts. See <a href="./config_os.html">Deactivate or Configure SELinux</a>.</p></blockquote><h3 id="java" tabindex="-1"><a id="topic_xbl_mkx_zgb"></a>Java <a class="header-anchor" href="#java" aria-label="Permalink to &quot;&lt;a id=&quot;topic_xbl_mkx_zgb&quot;&gt;&lt;/a&gt;Java&quot;">​</a></h3><p>WarehousePGd 7 supports these Java versions for PL/Java and PXF:</p><ul><li>Open JDK 8 or Open JDK 11, available from <a href="https://adoptopenjdk.net" target="_blank" rel="noreferrer">AdoptOpenJDK</a></li><li>Oracle JDK 8 or Oracle JDK 11</li></ul><h3 id="python" tabindex="-1"><a id="topic_xbl_mkx_python"></a>Python <a class="header-anchor" href="#python" aria-label="Permalink to &quot;&lt;a id=&quot;topic_xbl_mkx_python&quot;&gt;&lt;/a&gt;Python&quot;">​</a></h3><p>WarehousePG uses the system default <code>python3</code> for the WarehousePG management utilities, and <code>python3.11</code> for the <a href="./../analytics/pl_python.html">PL/Python module</a>. For most of the supported OS versions, the system default <code>python3</code> is <code>python3.9</code>. If you are installing WarehousePG on Rocky Linux 8, the default <code>python3</code> version included is <code>python3.6</code>. You may want to unify the <code>python3</code> versions to <code>python3.11</code> by running the following commands:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>sudo yum install python3.11 python3.11-devel python3.11-psycopg2 python3.11-pyyaml python3.11-psutil</span></span>
<span class="line"><span>sudo update-alternatives set python3 /usr/bin/python3.11</span></span>
<span class="line"><span>sudo update-alternatives set python /usr/bin/python3.11</span></span></code></pre></div><h2 id="warehousepg-tools-and-extensions-compatibility" tabindex="-1"><a id="topic31"></a>WarehousePG Tools and Extensions Compatibility <a class="header-anchor" href="#warehousepg-tools-and-extensions-compatibility" aria-label="Permalink to &quot;&lt;a id=&quot;topic31&quot;&gt;&lt;/a&gt;WarehousePG Tools and Extensions Compatibility&quot;">​</a></h2><h3 id="client-tools" tabindex="-1"><a id="topic32"></a>Client Tools <a class="header-anchor" href="#client-tools" aria-label="Permalink to &quot;&lt;a id=&quot;topic32&quot;&gt;&lt;/a&gt;Client Tools&quot;">​</a></h3><p>The WarehousePG 7 Clients tool package is supported on the following platforms:</p><ul><li>Red Hat Enterprise Linux x86_64 8.x (RHEL 8)</li><li>Oracle Linux 64-bit 8, using the Red Hat Compatible Kernel (RHCK)</li><li>Rocky Linux 8</li><li>Windows 10 (64-bit)</li><li>Windows 8 (64-bit)</li><li>Windows Server 2012 (64-bit)</li><li>Windows Server 2012 R2 (64-bit)</li><li>Windows Server 2008 R2 (64-bit)</li></ul><p>The WarehousePG 7 Clients package includes the client and loader programs plus database/role/language commands. Refer to WarehousePG Client and Loader Tools Package for installation and usage details of the WarehousePG 7 Client tools.</p><h3 id="extensions" tabindex="-1"><a id="topic_eyc_l2h_zz"></a>Extensions <a class="header-anchor" href="#extensions" aria-label="Permalink to &quot;&lt;a id=&quot;topic_eyc_l2h_zz&quot;&gt;&lt;/a&gt;Extensions&quot;">​</a></h3><p>This table lists the versions of the WarehousePG Extensions that are compatible with this release of WarehousePG 7.</p>`,28),e("div",{class:"tablenoborder"},[e("table",{cellpadding:"4",cellspacing:"0",summary:"",id:"topic_eyc_l2h_zz__table_b1q_m2h_zz",class:"table",frame:"border",border:"1",rules:"all"},[e("caption",null,[e("span",{class:"tablecap"},"WarehousePG Extensions Compatibility ")]),e("colgroup",null,[e("col"),e("col"),e("col")]),e("thead",{class:"thead",style:{"text-align":"left"}},[e("tr",{class:"row"},[e("th",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},id:"d78288e683"},"Component"),e("th",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},id:"d78288e686"},"Package Version"),e("th",{class:"entry cell-norowborder",style:{"vertical-align":"top"},id:"d78288e689"},"Additional Information")])]),e("tbody",{class:"tbody"},[e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e683 "},[e("a",{class:"xref",href:"../analytics/pl_java.html"},"PL/Java")]),e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e686 "},"2.0.7"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"},headers:"d78288e689 "},"Supports Java 8 and 11.")]),e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e683 "},[e("a",{class:"xref",href:"../install_guide/install_python_dsmod.html"},"Python 3.11 Data Science Module Package")]),e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e686 "},"1.2"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"},headers:"d78288e689 "}," ")]),e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e683 "},[e("a",{class:"xref",href:"../analytics/pl_r.html"},"PL/R")]),e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e686 "},"3.1.1"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"},headers:"d78288e689 "},[t("(CentOS) R 3.3.3"),e("p",{class:"p"}," (Ubuntu) You install R 3.5.1+.")])]),e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e683 "},[e("a",{class:"xref",href:"../install_guide/install_r_dslib.html"},"R Data Science Library Package")]),e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e686 "},"2.0.2"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"},headers:"d78288e689 "}," ")]),e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e683 "},[e("a",{class:"xref",href:"../analytics/pl_container.html"},"PL/Container")]),e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e686 "},"2.2.1"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"},headers:"d78288e689 "}," ")]),e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e683 "},"PL/Container Image for R "),e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e686 "},"2.1.2"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"},headers:"d78288e689 "},"R 3.6.3")]),e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e683 "},"PL/Container Images for Python "),e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e686 "},"2.1.2"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"},headers:"d78288e689 "},[t("Python 2.7.12"),e("p",{class:"p"},"Python 3.7")])]),e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e683 "},[e("a",{class:"xref",href:"../analytics/madlib.html"},"MADlib Machine Learning")]),e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"},headers:"d78288e686 "},"2.1.0"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"},headers:"d78288e689 "},[t("Support matrix at "),e("a",{class:"xref",href:"https://cwiki.apache.org/confluence/display/MADLIB/FAQ#FAQ-Q1-2WhatdatabaseplatformsdoesMADlibsupportandwhatistheupgradematrix?",target:"_blank"},"MADlib FAQ"),t(".")])]),e("tr",{class:"row"},[e("td",{class:"entry row-nocellborder",style:{"vertical-align":"top"},headers:"d78288e683 "},[e("a",{class:"xref",href:"../analytics/postGIS.html"},"PostGIS Spatial and Geographic Objects")]),e("td",{class:"entry row-nocellborder",style:{"vertical-align":"top"},headers:"d78288e686 "},"3.3.2"),e("td",{class:"entry cellrowborder",style:{"vertical-align":"top"},headers:"d78288e689 "}," ")])])])],-1),a('<p>For information about the Oracle Compatibility Functions, see <a href="./../ref_guide/modules/orafce_ref.html">Oracle Compatibility Functions</a>.</p><p>These WarehousePG extensions are installed with WarehousePG</p><ul><li>Fuzzy String Match Extension</li><li>PL/Python Extension</li><li>pgcrypto Extension</li></ul><h3 id="data-connectors" tabindex="-1"><a id="topic_xpf_25b_hbb"></a>Data Connectors <a class="header-anchor" href="#data-connectors" aria-label="Permalink to &quot;&lt;a id=&quot;topic_xpf_25b_hbb&quot;&gt;&lt;/a&gt;Data Connectors&quot;">​</a></h3><ul><li>WarehousePG Platform Extension Framework (PXF) - PXF provides access to Hadoop, object store, and SQL external data stores. Refer to <a href="./../admin_guide/external/pxf-overview.html">Accessing External Data with PXF</a> in the <em>WarehousePG Administrator Guide</em> for PXF configuration and usage information.</li><li>WarehousePG Connector for Apache Spark v1.6.2 - The WarehousePG Connector for Apache Spark supports high speed, parallel data transfer between WarehousePG and an Apache Spark cluster using Spark’s Scala API.</li><li>WarehousePG Connector for Apache NiFi v1.0.0 - The WarehousePG Connector for Apache NiFi enables you to set up a NiFi dataflow to load record-oriented data from any source into WarehousePG.</li><li>R2B X-LOG v5.x and v6.x - Real-time data replication solution that achieves high-speed database replication through the use of Redo Log Capturing method.</li></ul><h2 id="hardware-requirements" tabindex="-1"><a id="topic_tnl_3mx_zgb"></a>Hardware Requirements <a class="header-anchor" href="#hardware-requirements" aria-label="Permalink to &quot;&lt;a id=&quot;topic_tnl_3mx_zgb&quot;&gt;&lt;/a&gt;Hardware Requirements&quot;">​</a></h2><p>The following table lists minimum recommended specifications for hardware servers intended to support WarehousePG on Linux systems in a production environment. All host servers in your WarehousePG cluster must have the same hardware and software configuration. WarehousePG also provides hardware build guides for its certified hardware platforms. Work with a WarehousePG clusters Engineer to review your anticipated environment to ensure an appropriate hardware configuration for WarehousePG.</p>',7),e("div",{class:"tablenoborder"},[e("table",{cellpadding:"4",cellspacing:"0",summary:"",id:"topic_tnl_3mx_zgb__ji162790",class:"table",frame:"border",border:"1",rules:"all"},[e("caption",null,[e("span",{class:"tablecap"},"Minimum Hardware Requirements")]),e("colgroup",null,[e("col",{style:{width:"120pt"}}),e("col",{style:{width:"255pt"}})]),e("tbody",{class:"tbody"},[e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"}},"Minimum CPU"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"}},"Any x86_64 compatible CPU")]),e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"}},"Minimum Memory"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"}},"16 GB RAM per server")]),e("tr",{class:"row"},[e("td",{class:"entry nocellnorowborder",style:{"vertical-align":"top"}},"Disk Space Requirements"),e("td",{class:"entry cell-norowborder",style:{"vertical-align":"top"}},[e("ul",{class:"ul",id:"topic_tnl_3mx_zgb__ul_us1_b4n_r4"},[e("li",{class:"li"},"150MB per host for WarehousePG installation"),e("li",{class:"li"},"Approximately 300MB per segment instance for metadata"),e("li",{class:"li"},"Cap disk capacity at 70% full to accommodate temporary files and prevent performance degradation")])])]),e("tr",{class:"row"},[e("td",{class:"entry row-nocellborder",style:{"vertical-align":"top"}},"Network Requirements"),e("td",{class:"entry cellrowborder",style:{"vertical-align":"top"}},[t("10 Gigabit Ethernet within the array"),e("p",{class:"p"},"NIC bonding is recommended when multiple interfaces are present"),e("p",{class:"p"},"WarehousePG can use either IPV4 or IPV6 protocols.")])])])])],-1),a('<p><strong>Hyperthreading</strong></p><p>Resource Groups - one of the key WarehousePG features - can control transaction concurrency, CPU and memory resources, workload isolation, and dynamic bursting.</p><p>When using resource groups to control resource allocation on Intel based systems, consider switching off Hyper-Threading (HT) in the server BIOS (for Intel cores the default is ON). Switching off HT might cause a small throughput reduction (less than 15%), but can achieve greater isolation between resource groups, and higher query performance with lower concurrency workloads.</p><h2 id="storage" tabindex="-1"><a id="topic_pnz_5zd_xs"></a>Storage <a class="header-anchor" href="#storage" aria-label="Permalink to &quot;&lt;a id=&quot;topic_pnz_5zd_xs&quot;&gt;&lt;/a&gt;Storage&quot;">​</a></h2><p>The only file system supported for running WarehousePG is the XFS file system. All other file systems are explicitly <em>not</em> supported by WarehousePG.</p><p>WarehousePG is supported on network or shared storage if the shared storage is presented as a block device to the servers running WarehousePG and the XFS file system is mounted on the block device. Network file systems are <em>not</em> supported. When using network or shared storage, WarehousePG mirroring must be used in the same way as with local storage, and no modifications may be made to the mirroring scheme or the recovery scheme of the segments.</p><p>Other features of the shared storage such as de-duplication and/or replication are not directly supported by WarehousePG, but may be used with support of the storage vendor as long as they do not interfere with the expected operation of WarehousePG.</p><p>WarehousePG can be deployed to virtualized systems only if the storage is presented as block devices and the XFS file system is mounted for the storage of the segment directories.</p><p>WarehousePG is supported on Amazon Web Services (AWS) servers using either Amazon instance store (Amazon uses the volume names <code>ephemeral[0-23]</code>) or Amazon Elastic Block Store (Amazon EBS) storage. If using Amazon EBS storage the storage should be RAID of Amazon EBS volumes and mounted with the XFS file system for it to be a supported configuration.</p><h2 id="hadoop-distributions" tabindex="-1"><a id="topic36"></a>Hadoop Distributions <a class="header-anchor" href="#hadoop-distributions" aria-label="Permalink to &quot;&lt;a id=&quot;topic36&quot;&gt;&lt;/a&gt;Hadoop Distributions&quot;">​</a></h2><p>WarehousePG provides access to HDFS with the WarehousePG Platform Extension Framework PXF</p><p>PXF can use Cloudera, Hortonworks Data Platform, MapR, and generic Apache Hadoop distributions. PXF bundles all of the JAR files on which it depends, including the following Hadoop libraries:</p><table tabindex="0"><thead><tr><th>PXF Version</th><th>Hadoop Version</th><th>Hive Server Version</th><th>HBase Server Version</th></tr></thead><tbody><tr><td>6.x, 5.15.x, 5.14.0, 5.13.0, 5.12.0, 5.11.1, 5.10.1</td><td>2.x, 3.1+</td><td>1.x, 2.x, 3.1+</td><td>1.3.2</td></tr><tr><td>5.8.2</td><td>2.x</td><td>1.x</td><td>1.3.2</td></tr><tr><td>5.8.1</td><td>2.x</td><td>1.x</td><td>1.3.2</td></tr></tbody></table><blockquote><p><strong>Note</strong> If you plan to access JSON format data stored in a Cloudera Hadoop cluster, PXF requires a Cloudera version 5.8 or later Hadoop distribution.</p></blockquote><h2 id="public-cloud-requirements" tabindex="-1"><a id="public-cloud"></a>Public Cloud Requirements <a class="header-anchor" href="#public-cloud-requirements" aria-label="Permalink to &quot;&lt;a id=&quot;public-cloud&quot;&gt;&lt;/a&gt;Public Cloud Requirements&quot;">​</a></h2><h3 id="operating-system" tabindex="-1"><a id="cd-os"></a>Operating System <a class="header-anchor" href="#operating-system" aria-label="Permalink to &quot;&lt;a id=&quot;cd-os&quot;&gt;&lt;/a&gt;Operating System&quot;">​</a></h3><p>The operating system parameters for cloud deployments are the same as on-premise with a few modifications. Use the <a href="./../install_guide/install_guide/">WarehousePG Installation Guide</a> for reference. Additional changes are as follows:</p><p>Add the following line to <code>sysctl.conf</code>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>net.ipv4.ip_local_reserved_ports=65330</span></span></code></pre></div><p>AWS requires loading network drivers and also altering the Amazon Machine Image (AMI) to use the faster networking capabilities. More information on this is provided in the AWS documentation.</p><h3 id="storage-1" tabindex="-1"><a id="cd-storage"></a>Storage <a class="header-anchor" href="#storage-1" aria-label="Permalink to &quot;&lt;a id=&quot;cd-storage&quot;&gt;&lt;/a&gt;Storage&quot;">​</a></h3><p>The disk settings for cloud deployments are the same as on-premise with a few modifications. Use the <a href="./../install_guide/install_guide/">WarehousePG Installation Guide</a> for reference. Additional changes are as follows:</p><ul><li>Mount options:<div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>rw,noatime,nobarrier,nodev,inode64</span></span></code></pre></div><blockquote><p><strong>Note</strong> The <code>nobarrier</code> option is not supported on RHEL 8 or Ubuntu nodes.</p></blockquote></li><li>Use mq-deadline instead of the deadline scheduler for the R5 series instance type in AWS</li><li>Use a swap disk per VM (32GB size works well)</li></ul><h3 id="amazon-web-services-aws" tabindex="-1"><a id="aws"></a>Amazon Web Services (AWS) <a class="header-anchor" href="#amazon-web-services-aws" aria-label="Permalink to &quot;&lt;a id=&quot;aws&quot;&gt;&lt;/a&gt;Amazon Web Services (AWS)&quot;">​</a></h3><h4 id="virtual-machine-type" tabindex="-1"><a id="aws-vm-type"></a>Virtual Machine Type <a class="header-anchor" href="#virtual-machine-type" aria-label="Permalink to &quot;&lt;a id=&quot;aws-vm-type&quot;&gt;&lt;/a&gt;Virtual Machine Type&quot;">​</a></h4><p>AWS provides a wide variety of virtual machine types and sizes to address virtually every use case. Testing in AWS has found that the optimal instance types for WarehousePG are &quot;Memory Optimized&quot;. These provide the ideal balance of Price, Memory, Network, and Storage throughput, and Compute capabilities.</p><p>Price, Memory, and number of cores typically increase in a linear fashion, but the network speed and disk throughput limits do not. You may be tempted to use the largest instance type to get the highest network and disk speed possible per VM, but better overall performance for the same spend on compute resources can be obtained by using more VMs that are smaller in size.</p><h5 id="compute" tabindex="-1"><a id="aws-compute"></a>Compute <a class="header-anchor" href="#compute" aria-label="Permalink to &quot;&lt;a id=&quot;aws-compute&quot;&gt;&lt;/a&gt;Compute&quot;">​</a></h5><p>AWS uses Hyperthreading when reporting the number of vCPUs, therefore 2 vCPUs equates to 1 Core. The processor types are frequently getting faster so using the latest instance type will be not only faster, but usually less expensive. For example, the R5 series provides faster cores at a lower cost compared to R4.</p><h5 id="memory" tabindex="-1"><a id="aws-memory"></a>Memory <a class="header-anchor" href="#memory" aria-label="Permalink to &quot;&lt;a id=&quot;aws-memory&quot;&gt;&lt;/a&gt;Memory&quot;">​</a></h5><p>This variable is pretty simple. WarehousePG needs at least 8GB of RAM per segment process to work optimally. More RAM per segment helps with concurrency and also helps hide disk performance deficiencies.</p><h5 id="network" tabindex="-1"><a id="aws-network"></a>Network <a class="header-anchor" href="#network" aria-label="Permalink to &quot;&lt;a id=&quot;aws-network&quot;&gt;&lt;/a&gt;Network&quot;">​</a></h5><p>AWS provides 25Gbit network performance on the largest instance types, but the network is typically not the bottleneck in AWS. The &quot;up to 10Gbit&quot; network is sufficient in AWS.</p><p>Installing network drivers in the VM is also required in AWS, and depends on the instance type. Some instance types use an Intel driver while others use an Amazon ENA driver. Loading the driver requires modifying the machine image (AMI) to take advantage of the driver.</p><h4 id="storage-2" tabindex="-1"><a id="storage"></a>Storage <a class="header-anchor" href="#storage-2" aria-label="Permalink to &quot;&lt;a id=&quot;storage&quot;&gt;&lt;/a&gt;Storage&quot;">​</a></h4><h5 id="elastic-block-storage-ebs" tabindex="-1"><a id="aws-ebs"></a>Elastic Block Storage (EBS) <a class="header-anchor" href="#elastic-block-storage-ebs" aria-label="Permalink to &quot;&lt;a id=&quot;aws-ebs&quot;&gt;&lt;/a&gt;Elastic Block Storage (EBS)&quot;">​</a></h5><p>The AWS default disk type is General Performance (GP2) which is ideal for IOP dependent applications. GP2 uses SSD disks and relative to other disk types in AWS, is expensive. The operating system and swap volumes are ideal for GP2 disks because of the size and higher random I/O needs.</p><p>Throughput Optimized Disks (ST1) are a disk type designed for high throughput needs such as WarehousePG. These disks are based on HDD rather than SSD, and are less expensive than GP2. Use this disk type for the optimal performance of loading and SQL: Querying Data in AWS.</p><p>Cold Storage (SC1) provides the best value for EBS storage in AWS. Using multiple 2TB or larger disks provides enough disk throughput to reach the throughput limit of many different instance types. Therefore, it is possible to reach the throughput limit of a VM by using SC1 disks.</p><p>EBS storage is durable so data is not lost when a virtual machine is stopped. EBS also provides infrastructure snapshot capabilities that can be used to create volume backups. These snapshots can be copied to different regions to provide a disaster recovery solution. The WarehousePG Cloud utility <code>gpsnap</code>, available in the AWS Cloud Marketplace, automates backup, restore, delete, and copy functions using EBS snapshots.</p><p>Storage can be grown in AWS with &quot;gpgrow&quot;. This tool is included with the WarehousePG on AWS deployment and allows you to grow the storage independently of compute. This is an online operation in AWS too.</p><h5 id="ephemeral" tabindex="-1"><a id="aws-ephemeral"></a>Ephemeral <a class="header-anchor" href="#ephemeral" aria-label="Permalink to &quot;&lt;a id=&quot;aws-ephemeral&quot;&gt;&lt;/a&gt;Ephemeral&quot;">​</a></h5><p>Ephemeral Storage is directly attached to VMs, but has many drawbacks:</p><ul><li>Data loss when stopping a VM with ephemeral storage</li><li>Encryption is not supported</li><li>No Snapshots</li><li>Same speed can be achieved with EBS storage</li><li>Not recommended</li></ul><h5 id="aws-recommendations" tabindex="-1"><a id="aws-recommend"></a>AWS Recommendations <a class="header-anchor" href="#aws-recommendations" aria-label="Permalink to &quot;&lt;a id=&quot;aws-recommend&quot;&gt;&lt;/a&gt;AWS Recommendations&quot;">​</a></h5><h6 id="coordinator" tabindex="-1">Coordinator <a class="header-anchor" href="#coordinator" aria-label="Permalink to &quot;Coordinator&quot;">​</a></h6><table tabindex="0"><thead><tr><th>Instance Type</th><th>Memory</th><th>vCPUs</th><th>Data Disks</th></tr></thead><tbody><tr><td>r5.xlarge</td><td>32</td><td>4</td><td>1</td></tr><tr><td>r5.2xlarge</td><td>64</td><td>8</td><td>1</td></tr><tr><td>r5.4xlarge</td><td>128</td><td>16</td><td>1</td></tr></tbody></table><h6 id="segments" tabindex="-1">Segments <a class="header-anchor" href="#segments" aria-label="Permalink to &quot;Segments&quot;">​</a></h6><table tabindex="0"><thead><tr><th>Instance Type</th><th>Memory</th><th>vCPUs</th><th>Data Disks</th></tr></thead><tbody><tr><td>r5.4xlarge</td><td>128</td><td>16</td><td>3</td></tr></tbody></table><p>Performance testing has indicated that the Coordinator node can be deployed on the smallest r5.xlarge instance type to save money without a measurable difference in performance. Testing was performed using the TPC-DS benchmark.</p><p>The Segment instances run optimally on the r5.4xlarge instance type. This provides the highest performance given the cost of the AWS resources.</p><h3 id="google-compute-platform-gcp" tabindex="-1"><a id="gcp"></a>Google Compute Platform (GCP) <a class="header-anchor" href="#google-compute-platform-gcp" aria-label="Permalink to &quot;&lt;a id=&quot;gcp&quot;&gt;&lt;/a&gt;Google Compute Platform (GCP)&quot;">​</a></h3><h4 id="virtual-machine-type-1" tabindex="-1"><a id="gcp-vm-type"></a>Virtual Machine Type <a class="header-anchor" href="#virtual-machine-type-1" aria-label="Permalink to &quot;&lt;a id=&quot;gcp-vm-type&quot;&gt;&lt;/a&gt;Virtual Machine Type&quot;">​</a></h4><p>The two most common instance types in GCP are &quot;Standard&quot; or &quot;HighMem&quot; instance types. The only difference is the ratio of Memory to Cores. Each offer 1 to 64 vCPUs per VM.</p><h5 id="compute-1" tabindex="-1"><a id="gcp-compute"></a>Compute <a class="header-anchor" href="#compute-1" aria-label="Permalink to &quot;&lt;a id=&quot;gcp-compute&quot;&gt;&lt;/a&gt;Compute&quot;">​</a></h5><p>Like AWS, GCP uses Hyperthreading, so 2 vCPUs equates to 1 Core. The CPU clock speed is determined by the region in which you deploy.</p><h5 id="memory-1" tabindex="-1"><a id="gcp-memory"></a>Memory <a class="header-anchor" href="#memory-1" aria-label="Permalink to &quot;&lt;a id=&quot;gcp-memory&quot;&gt;&lt;/a&gt;Memory&quot;">​</a></h5><p>Instance type n1-standard-8 has 8 vCPUs with 30GB of RAM while n1-highmem-8 also has 8 vCPUs with 52GB of RAM. There is also a HighCPU instance type that generally isn&#39;t ideal for WarehousePG. Like AWS and Azure, the machines with more vCPUs will have more RAM.</p><h5 id="network-1" tabindex="-1"><a id="gcp-network"></a>Network <a class="header-anchor" href="#network-1" aria-label="Permalink to &quot;&lt;a id=&quot;gcp-network&quot;&gt;&lt;/a&gt;Network&quot;">​</a></h5><p>GCP network speeds are dependent on the instance type but the maximum network performance is possible (10Gbit) with a virtual machine as small as only 8 vCPUs.</p><h4 id="storage-3" tabindex="-1"><a id="gcp-storage"></a>Storage <a class="header-anchor" href="#storage-3" aria-label="Permalink to &quot;&lt;a id=&quot;gcp-storage&quot;&gt;&lt;/a&gt;Storage&quot;">​</a></h4><p>Standard (HDD) and SSD disks are available in GCP. SSD is slightly faster in terms of throughput but comes at a premium. The size of the disk does not impact performance.</p><p>The biggest obstacle to maximizing storage performance is the throughput limit placed on every virtual machine. Unlike AWS and Azure, the storage throughput limit is relatively low, consistent across all instance types, and only a single disk is needed to reach the VM limit.</p><p><img src="'+n+'" alt="GCP disk read/write rates"></p><h4 id="gcp-recommendations" tabindex="-1"><a id="gcp-recommend"></a>GCP Recommendations <a class="header-anchor" href="#gcp-recommendations" aria-label="Permalink to &quot;&lt;a id=&quot;gcp-recommend&quot;&gt;&lt;/a&gt;GCP Recommendations&quot;">​</a></h4><p>Testing has revealed that <em>while using the same number of vCPUs</em>, a cluster using a large instance type like n1-highmem-64 (64 vCPUs) will have lower performance than a cluster using more of the smaller instance types like n1-highmem-8 (8 vCPUs). In general, use 8x more nodes in GCP than you would in another environment like AWS while using the 8 vCPU instance types.</p><p>The HighMem instance type is slightly faster for higher concurrency. Furthermore, SSD disks are slightly faster also but come at a cost.</p><h6 id="coordinator-and-segment-instances" tabindex="-1">Coordinator and Segment Instances <a class="header-anchor" href="#coordinator-and-segment-instances" aria-label="Permalink to &quot;Coordinator and Segment Instances&quot;">​</a></h6><table tabindex="0"><thead><tr><th>Instance Type</th><th>Memory</th><th>vCPUs</th><th>Data Disks</th></tr></thead><tbody><tr><td>n1-standard-8</td><td>30</td><td>8</td><td>1</td></tr><tr><td>n1-highmem-8</td><td>52</td><td>8</td><td>1</td></tr></tbody></table><h3 id="azure" tabindex="-1"><a id="azure"></a>Azure <a class="header-anchor" href="#azure" aria-label="Permalink to &quot;&lt;a id=&quot;azure&quot;&gt;&lt;/a&gt;Azure&quot;">​</a></h3><blockquote><p><strong>Note</strong> On the Azure platform, in addition to bandwidth, the number of network connections present on a VM at any given moment can affect the VM&#39;s network performance. The Azure networking stack maintains the state for each direction of a TCP/UDP connection in a data structures called a <em>flow</em>. A typical TCP/UDP connection will have 2 flows created: one for the inbound direction and another for the outbound direction. The number of network flows on Azure is limited to an upper bound. See <a href="https://docs.microsoft.com/bs-latn-ba/azure/virtual-network/virtual-machine-network-throughput" target="_blank" rel="noreferrer">Virtual machine network bandwidth</a> in the Azure documentation for more details. In practice this can present scalability challenges for workloads based on the number of concurrent queries, and on the complexity of those queries. Always test your workload on Azure to validate that you are within the Azure limits, and be advised that if your workload increases you may hit Azure flow count boundaries at which point your workload may fail. It is recomended to use the UDP interconnect, and not the TCP interconnect, when using Azure. A connection pooler and resource group settings can also be used to help keep flow counts at a lower level.</p></blockquote><h4 id="virtual-machine-type-2" tabindex="-1"><a id="az-vm-type"></a>Virtual Machine Type <a class="header-anchor" href="#virtual-machine-type-2" aria-label="Permalink to &quot;&lt;a id=&quot;az-vm-type&quot;&gt;&lt;/a&gt;Virtual Machine Type&quot;">​</a></h4><p>Each VM type has limits on disk throughput so picking a VM that doesn&#39;t have a limit that is too low is essential. Most of Azure is designed for OLTP or Application workloads, which limits the choices for databases like WarehousePG where throughput is more important. Disk type also plays a part in the throughput cap, so that needs to be considered too.</p><h4 id="compute-2" tabindex="-1"><a id="az-compute"></a>Compute <a class="header-anchor" href="#compute-2" aria-label="Permalink to &quot;&lt;a id=&quot;az-compute&quot;&gt;&lt;/a&gt;Compute&quot;">​</a></h4><p>Most instance types in Azure have hyperthreading enabled, which means 1 vCPU equates to 2 cores. However, not all instance types have this feature, so for these others, 1 vCPU equates to 1 core.</p><p>The High Performance Compute (HPC) instance types have the fastest cores in Azure.</p><h4 id="memory-2" tabindex="-1"><a id="az-memory"></a>Memory <a class="header-anchor" href="#memory-2" aria-label="Permalink to &quot;&lt;a id=&quot;az-memory&quot;&gt;&lt;/a&gt;Memory&quot;">​</a></h4><p>In general, the larger the virtual machine type, the more memory the VM will have.</p><h4 id="network-2" tabindex="-1"><a id="az-network"></a>Network <a class="header-anchor" href="#network-2" aria-label="Permalink to &quot;&lt;a id=&quot;az-network&quot;&gt;&lt;/a&gt;Network&quot;">​</a></h4><p>The Accelerated Networking option offloads CPU cycles for networking to &quot;FPGA-based SmartNICs&quot;. Virtual machine types either support this or do not, but most do support it. Testing of WarehousePG hasn&#39;t shown much difference and this is probably because of Azure&#39;s preference for TCP over UDP. Despite this, UDPIFC interconnect is the ideal protocol to use in Azure.</p><p>There is an undocumented process in Azure that periodically runs on the host machines on UDP port 65330. When a query runs using UDP port 65330 and this undocumented process runs, the query will fail after one hour with an interconnect timeout error. This is fixed by reserving port 65330 so that WarehousePG doesn&#39;t use it.</p><h4 id="storage-4" tabindex="-1"><a id="az-storage"></a>Storage <a class="header-anchor" href="#storage-4" aria-label="Permalink to &quot;&lt;a id=&quot;az-storage&quot;&gt;&lt;/a&gt;Storage&quot;">​</a></h4><p>Storage in Azure is either Premium (SSD) or Regular Storage (HDD). The available sizes are the same and max out at 4TB. Instance types either do or do not support Premium but, interestingly, the instance types that do support Premium storage, have a <em>lower</em> throughput limit. For example:</p><ul><li>Standard_E32s_v3 has a limit of 768 MB/s.</li><li>Standard_E32_v3 was tested with <code>gpcheckperf</code> to have 1424 write and 1557 read MB/s performance.</li></ul><p>To get the maximum throughput from a VM in Azure, you have to use multiple disks. For larger instance types, you have to use upwards of 32 disks to reach the limit of a VM. Unfortunately, the memory and CPU constraints on these machines means that you have to run fewer segments than you have disks, so you have to use software RAID to utilize all of these disks. Performance takes a hit with software RAID, too, so you have to try multiple configurations to optimize.</p><p>The size of the disk also impacts performance, but not by much.</p><p>Software RAID not only is a little bit slower, but it also requires <code>umount</code> to take a snapshot. This greatly lengthens the time it takes to take a snapshot backup.</p><p>Disks use the same network as the VMs so you start running into the Azure limits in bigger clusters when using big virtual machines with 32 disks on each one. The overall throughput drops as you hit this limit and is most noticeable during concurrency testing.</p><h4 id="azure-recommendations" tabindex="-1"><a id="az-recommend"></a>Azure Recommendations <a class="header-anchor" href="#azure-recommendations" aria-label="Permalink to &quot;&lt;a id=&quot;az-recommend&quot;&gt;&lt;/a&gt;Azure Recommendations&quot;">​</a></h4><p>The best instance type to use in Azure is &quot;Standard_H8&quot; which is one of the High Performance Compute instance types. This instance series is the only one utilizing InfiniBand, but this does not include IP traffic. Because this instance type is n0t available in all regions, the &quot;Standard_D13_v2&quot; is also available.</p><h6 id="coordinator-1" tabindex="-1">Coordinator <a class="header-anchor" href="#coordinator-1" aria-label="Permalink to &quot;Coordinator&quot;">​</a></h6><table tabindex="0"><thead><tr><th>Instance Type</th><th>Memory</th><th>vCPUs</th><th>Data Disks</th></tr></thead><tbody><tr><td>D13_v2</td><td>56</td><td>8</td><td>1</td></tr><tr><td>H8</td><td>56</td><td>8</td><td>1</td></tr></tbody></table><h6 id="segments-1" tabindex="-1">Segments <a class="header-anchor" href="#segments-1" aria-label="Permalink to &quot;Segments&quot;">​</a></h6><table tabindex="0"><thead><tr><th>Instance Type</th><th>Memory</th><th>vCPUs</th><th>Data Disks</th></tr></thead><tbody><tr><td>D13_v2</td><td>56</td><td>8</td><td>2</td></tr><tr><td>H8</td><td>56</td><td>8</td><td>2</td></tr></tbody></table>',94)]))}const b=r(l,[["render",d]]);export{y as __pageData,b as default};
